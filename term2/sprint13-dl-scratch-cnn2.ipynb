{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.Z = 0\n",
    "        self.dA = 0\n",
    "        self.dW = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.Z = deepcopy(X)\n",
    "        A = np.dot(X, self.W) + self.B\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dA = deepcopy(dA)\n",
    "        self.dW = np.dot(self.Z.T, dA) / len(self.dA)\n",
    "        dZ = np.dot(dA, self.W.T) \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     48,
     90
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2=None):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        if n_nodes2 is None:\n",
    "            W = self.sigma * np.random.randn(n_nodes1, 1)\n",
    "        else:\n",
    "            W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "            \n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")\n",
    "    \n",
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierによる初期化\n",
    "    Sigmoid」かTanhに向いている\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")\n",
    "    \n",
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heによる初期化\n",
    "    ReLUと相性がいい\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sigma = 0\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = (self.sigma * np.random.randn(n_nodes1, n_nodes2))\n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     25,
     57,
     95
    ]
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W[...] = layer.W - self.lr * layer.dW\n",
    "        layer.B[...] = layer.B - self.lr * np.mean(layer.dA, axis=0, keepdims=True)\n",
    "        return layer\n",
    "\n",
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    学習率を変化を減少させていく勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        \n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        self.HW += dW**2\n",
    "        self.HB +=  dB**2\n",
    "        layer.W[...] = layer.W - self.lr / np.sqrt(self.HW +1e-7) * dW #0で割るとまずいので +le-7\n",
    "        layer.B[...] = layer.B - self.lr / np.sqrt(self.HB + 1e-7)  * dB\n",
    "        return layer\n",
    "    \n",
    "class Momentum:\n",
    "    \n",
    "    \"\"\"\n",
    "    momentumSGD\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    momentum : 学習係数\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.vW = 0\n",
    "        self.vB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "\n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        \n",
    "        self.vW = self.momentum * self.vW - self.lr * dW\n",
    "        self.vB =  self.momentum * self.vB - self.lr * dB\n",
    "        \n",
    "        layer.W[...] = layer.W + self.vW\n",
    "        layer.B[...] = layer.B + self.vB\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "class Adam:\n",
    "\n",
    "    \"\"\"\n",
    "    Adam\n",
    "    RMSprop に Momentum 法を組み合わせたような形\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    momentum : 学習係数\n",
    "    beta1\n",
    "    beta2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.mW = 0\n",
    "        self.vW = 0\n",
    "        self.mB = 0\n",
    "        self.vB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \n",
    "        self.iter += 1\n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        \n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter) \n",
    "        \n",
    "        self.mW += (1 - self.beta1) * (dW - self.mW)\n",
    "        self.vW += (1 - self.beta2) * (dW**2 - self.vW)\n",
    "        self.mB += (1 - self.beta1) * (dB - self.mB)\n",
    "        self.vB += (1 - self.beta2) * (dB**2 - self.vB)\n",
    "        \n",
    "        layer.W -= lr_t * self.mW / (np.sqrt(self.vW) + 1e-7)\n",
    "        layer.B -= lr_t * self.mB / (np.sqrt(self.vB) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     39,
     78,
     123
    ]
   },
   "outputs": [],
   "source": [
    "class sigmoid:\n",
    "    \"\"\"\n",
    "    シグモイド関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = 1 / (1 + np.exp(-A))\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ  *  (1 - self.Z) * self.Z \n",
    "        return dA\n",
    "    \n",
    "class Tanh:\n",
    "    \"\"\"\n",
    "    ハイパボリックタンジェント関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = np.tanh(A)\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ  *  (1 - self.Z**2)\n",
    "        return dA\n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"\n",
    "    ソフトマックス関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        \n",
    "        c = np.max(A)\n",
    "        A = A - c\n",
    "        ex = np.exp(A)\n",
    "        Z = ex / (np.sum(ex, axis=1))[:, np.newaxis]\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, y):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (batch_size, n_class)\n",
    "            正解ラベル\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_class)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        dA = self.Z - y\n",
    "        \n",
    "        return dA\n",
    "    \n",
    "class ReLU:\n",
    "    \"\"\"\n",
    "    ReLU関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = np.maximum(0, A)\n",
    "        self.Z = deepcopy(Z)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        dA = dZ  *  np.where(self.Z != 0, 1, self.Z)\n",
    "        \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    #Pythonの特殊メソッドのひとつで、オブジェクトに角括弧でアクセスしたときの挙動を定義できる。\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier2:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, batch_size=50, epoch=10, verbose=True, metrics=\"acc\"):\n",
    "        self.n_nodes = [n_features]\n",
    "        #self.n_output = n_output\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = epoch\n",
    "        self.metrics = metrics\n",
    "        self.verbose = verbose\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.layers = []\n",
    "\n",
    "    \n",
    "    def add(self, layer_type, n_nodes=None, Initializer=None, optimizer=None):\n",
    "        \n",
    "        if layer_type == \"FC\":\n",
    "            self.layers += [FC(self.n_nodes[-1], n_nodes, Initializer, optimizer)]\n",
    "            self.n_nodes += [n_nodes]\n",
    "            \n",
    "        elif layer_type == \"Conv1d\":\n",
    "            salf.layers += [SimpleConv1d(filter_size=3, in_channel=1, initializer=initializer, optimizer=optimizer, straid=1, pad=0, out_channel=1)]\n",
    "            self.n_nodes += [n_nodes]\n",
    "            \n",
    "        elif layer_type == \"ReLU\":\n",
    "            self.layers += [ReLU()]\n",
    "        \n",
    "        elif layer_type == \"Tanh\":\n",
    "            self.layers += [Tanh()]\n",
    "        \n",
    "        elif layer_type == \"sigmoid\":\n",
    "            self.layers += [sigmoid()]\n",
    "            \n",
    "        elif layer_type == \"Softmax\":\n",
    "            self.layers += [Softmax()]\n",
    "        else:\n",
    "            print(\"layer_typeが存在しません\")\n",
    "    \n",
    "    def add_sim(self, layer):\n",
    "        \n",
    "        self.layers += [layer]\n",
    "            \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epoch=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        epoch : int\n",
    "            エポック数変えたいときは入れてください\n",
    "        \"\"\"\n",
    "        if epoch:\n",
    "            self.epoch = epoch\n",
    "        \n",
    "        for i in range(self.epoch):\n",
    "\n",
    "            #バッチ作成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=56)\n",
    "\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                \n",
    "                #FP\n",
    "                self.FP(mini_X_train)\n",
    "\n",
    "                #BP\n",
    "                self.BP(mini_y_train)\n",
    "                \n",
    "            #評価値等の表示\n",
    "            train_pred = self.FP(X)\n",
    "            self.train_loss += [self._cross_entropy_loss(train_pred, y)]\n",
    "            \n",
    "            if np.any(X_val):\n",
    "                val_pred = self.FP(X_val)\n",
    "                self.val_loss += [self._cross_entropy_loss(val_pred, y_val)]\n",
    "                \n",
    "                #metricsを判定\n",
    "                if  self.metrics == \"acc\":\n",
    "                    met = self.accuracy(np.argmax(y_val, axis=1), np.argmax(val_pred, axis=1))\n",
    "                else:\n",
    "                    print(\"metricsの入力が間違っています\")\n",
    "                      \n",
    "                if self.verbose:\n",
    "                    print(\"epoch:{0} train_loss: {1} val_loss: {2} {3}: {4}\".format(i+1, self.train_loss[i], self.val_loss[i], self.metrics, met))\n",
    "                    \n",
    "            else:\n",
    "                if self.verbose:\n",
    "                      print(\"epoch:{0} loss: {1}\".format(i+1, self.train_loss[i]))\n",
    "     \n",
    "    def FP(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        return X\n",
    "            \n",
    "    def BP(self, y):\n",
    "        for layer in reversed(self.layers):\n",
    "            y = layer.backward(y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        hx = self.FP(X)\n",
    "        return np.argmax(hx, axis=1)\n",
    "            \n",
    "    def _cross_entropy_loss(self,z, y):\n",
    "        z += 1e-7\n",
    "        return - sum(sum(y * np.log(z))) / len(y)\n",
    "    \n",
    "    def accuracy(self, y, y_pred):\n",
    "        # accuracyを計算して返す\n",
    "        return accuracy_score(y, y_pred)\n",
    "    \n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        学習曲線をプロットします。\n",
    "\n",
    "        loss : array\n",
    "        一回ごとの勾配降下方のロスのログ(train)\n",
    "         val_los : array\n",
    "        一回ごとの勾配降下方のロスのログ(val or test)\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.title(\"model_loss\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.plot(self.train_loss, label=\"train_loss\")\n",
    "        plt.plot(self.val_loss, label=\"val_loss\")\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    convolutional layee\n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_size : int\n",
    "      フィルターのサイズ\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, filter_size, in_channel, initializer, optimizer, straid=1, pad=0, out_channel=1):\n",
    "        self.optimizer = optimizer\n",
    "        self.filter_size = filter_size\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(filter_size*in_channel, out_channel) #shape(filter_size*in_channel, out_cannel)\n",
    "        self.B = initializer.B(out_channel).reshape(1,-1) #shape(1, out_cannel)\n",
    "        self.out_size = None\n",
    "        self.out_channel = out_channel\n",
    "        self.straid = straid\n",
    "        self.CX = 0\n",
    "        self.dA = 0 #shape(batch_size, out_size)\n",
    "        self.dW = 0 \n",
    "        self.m = 0\n",
    "        self.n = 0\n",
    "        self.c = in_channel\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size,  n_feture, n_chanel)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, out_size, out_chanel)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        if X.ndim is 1:\n",
    "            X = X[np.newaxis, :, np.newaxis]\n",
    "        elif X.ndim is 2:\n",
    "            X = X[:, :, np.newaxis]\n",
    "        self.m = X.shape[0]\n",
    "        self.n = X.shape[1]\n",
    "        self.c = X.shape[2]\n",
    "        #out_sizeの計算\n",
    "        if self.out_size is None:\n",
    "            self.out_size = int((self.n + 2*self.pad - self.filter_size) / self.straid + 1)\n",
    "        \n",
    "        #並列計算のためXからデータを抜き出す CX shape(out_size*batch_size, filter_size*in_chanel)\n",
    "        #CX = np.empty((0, self.filter_size*self.c))\n",
    "        #for i in range(self.m):\n",
    "            #CX = np.vstack((CX, np.array([X[i, j*self.straid : j*self.straid+self.filter_size, k] for j in range(self.out_size) for k in range(self.c)]).reshape(-1, self.filter_size*self.c)))\n",
    "        indar = np.array([np.arange(j * self.straid, j*self.straid+self.filter_size) for j in range(self.out_size)])\n",
    "        #CX = X[:, :, ar].reshape(self.m*self.out_size, self.filter_size) \n",
    "        CX = X[:, indar, : ].reshape(self.out_size*self.m, self.filter_size*self.c).astype(\"f\")\n",
    "        self.CX = CX #shape(self.out_size*self.m, self.filter_size*self.c)\n",
    "        \n",
    "        A = np.dot(CX, self.W) + self.B #ここのA shape(batch_size*out_size, out_cahnnel)\n",
    "        A = A.reshape(self.m, self.out_size, self.out_channel) #ここのA shape(batch_size, out_size, out_cahnnel)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size,out_size,out_channel)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size,n_feture, in_channel)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        if dA.ndim is 1:\n",
    "            dA = dA[np.newaxis, :, np.newaxis]\n",
    "        elif dA.ndim is 2:\n",
    "            dA = dA[:, :, np.newaxis]\n",
    "            \n",
    "        self.dA = np.sum(dA, axis=1)\n",
    "        self.dW = np.dot(self.CX.T, dA.reshape(-1,self.out_channel)) #dAを shape(out_size*batch_size, out_channel)へ変形\n",
    "        \n",
    "        #ここからdZの計算\n",
    "        #dZの並列計算のためにdAのアレーを作成\n",
    "        da_ar = np.empty((0, self.filter_size*self.out_channel))\n",
    "        for i in range(self.m): #サンプル数分ループ\n",
    "            for j in range(self.n):\n",
    "                dalist = []\n",
    "                for k in range(self.out_channel):\n",
    "                    for s in range(self.filter_size):\n",
    "                        if  ((j - s) / self.straid < 0) or (j - s > self.out_size -1) or ((j - s) % self.straid  != 0):\n",
    "                            dalist += [0]\n",
    "                        else:\n",
    "                            dalist += [dA[i, j-s, k]]\n",
    "        \n",
    "                dalist = np.array(dalist)\n",
    "                da_ar = np.vstack((da_ar, dalist)) #da_ar shape(batch_size*X_fetures, filter_size*out_channel)\n",
    "        #indar = np.array([np.arange(j * self.straid, j*self.straid+self.filter_size) for j in range(self.out_size)])\n",
    "        #Wのshapeを変形(filter_size*out_channel, in_channel)\n",
    "        #ar = np.array([np.arange(i*self.straid,i*self.straid+self.filter_size)[::-1] for i in range(self.out_size)])\n",
    "        #dA = dA[:, ar, :].transpose(0,1,3,2).reshape(-1,self.filter_size*self.out_channel)\n",
    "\n",
    "        W = self.W.T.reshape(self.c, self.out_channel, self.filter_size).transpose(1,0,2).reshape(self.c, -1).T\n",
    "        dZ = np.dot(da_ar, W).reshape(self.m, self.n, self.c)\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "    def get_out_put_size(n_in, pad, filter_size, straid):\n",
    "        #一次元畳み込み後の出力サイズの計算\n",
    "        n_out = (n_in + 2*pad - filter_size) / straid + 1 \n",
    "        return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】平滑化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    #フラットにするだけのレイヤー\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.shape = X.shape\n",
    "        return X.reshape(self.shape[0], -1)\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        return dA.reshape(*self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】2次元畳み込み層の作成\n",
    "# 【問題2】2次元畳み込み後の出力サイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#今の所SimpleInitializer　と　SGDしか対応してません\n",
    "class Conv2d:\n",
    "    \"\"\"\n",
    "    convolutional layee\n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_size : int\n",
    "      フィルターのサイズ\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, filter_h, filter_w, in_channel, initializer, optimizer, straid=1, pad=0, out_channel=1):\n",
    "        self.optimizer = optimizer\n",
    "        self.filter_h = filter_h\n",
    "        self.filter_w = filter_w\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(filter_h*filter_w*in_channel, out_channel).reshape(out_channel, in_channel, filter_h, filter_w)\n",
    "        self.B = initializer.B(out_channel).reshape(1,-1) #shape(1, out_cannel)\n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        self.out_c = out_channel\n",
    "        self.straid = straid\n",
    "        self.Xcol = 0\n",
    "        self.dA = 0 #shape(batch_size, out_size)\n",
    "        self.dW = 0 \n",
    "        self.m = 0\n",
    "        self.h = 0\n",
    "        self.w = 0\n",
    "        self.c = in_channel\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, chanel, height, width)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, out_chanel, out_height, out_width)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        if X.ndim is 2:\n",
    "            X = X[np.newaxis, np.newaxis, :, :]\n",
    "        elif X.ndim is 3:\n",
    "            X = X[:, np.newaxis, :, :]\n",
    "            \n",
    "        self.m = X.shape[0]\n",
    "        self.h = X.shape[2]\n",
    "        self.w = X.shape[3]\n",
    "        \n",
    "        #out_sizeの計算\n",
    "        if self.out_h is None:\n",
    "            self.out_h = int((self.h + 2*self.pad - self.filter_h) / self.straid + 1)\n",
    "            self.out_w = int((self.w + 2*self.pad - self.filter_w) / self.straid + 1)\n",
    "        \n",
    "        #パディング\n",
    "        X = np.pad(X, [(0,0), (0,0), (self.pad, self.pad), (self.pad, self.pad)], 'constant')\n",
    "        \n",
    "        #m2col\n",
    "        col = np.zeros((self.m, self.c, self.filter_h, self.filter_w, self.out_h, self.out_w))\n",
    "        for y in range(self.filter_h):\n",
    "            y_max = y + self.straid*self.out_h\n",
    "            for x in range(self.filter_w):\n",
    "                x_max = x + self.straid*self.out_w\n",
    "                col[:, :, y, x, :, :] = X[:, :, y:y_max:self.straid, x:x_max:self.straid]\n",
    "                \n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(self.m*self.out_h*self.out_w, -1)\n",
    "        self.Xcol = col\n",
    "        self.Wcol = self.W.reshape(self.out_c, -1).T\n",
    "        A = np.dot(col, self.Wcol) + self.B.reshape(1,-1) #A shape(out_w*out_h*batch_size, out_c)\n",
    "        A = A.reshape(self.m, self.out_h, self.out_w, self.out_c).transpose(0,3,1,2)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size,　out_channel,　out_height,　out_width)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size,n_feture, in_channel)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        if dA.ndim is 1:\n",
    "            dA = dA[np.newaxis, :, np.newaxis]\n",
    "        elif dA.ndim is 2:\n",
    "            dA = dA[:, :, np.newaxis]\n",
    "        \n",
    "        self.dA = np.sum(np.sum(dA, axis=2),axis=2) #バイアスの計算用\n",
    "        #dAを shape(out_h*out_w*batchsize, out_channel)へ変形\n",
    "        dA = dA.transpose(0,2,3,1).reshape(-1, self.out_c)\n",
    "        #dWをWのshapeへ変形\n",
    "        self.dW = np.dot(self.Xcol.T, dA).T.reshape(self.out_c, self.c, self.filter_h, self.filter_w)\n",
    "        \n",
    "        dZcol = np.dot(dA, self.Wcol.T)\n",
    "        \n",
    "        #col2im\n",
    "        dZcol = dZcol.reshape(self.m, self.out_h, self.out_w, self.c, self.filter_h, self.filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        img = np.zeros((self.m, self.c, self.h + 2*self.pad + self.straid - 1, self.out_w + 2*self.pad + self.straid - 1))\n",
    "        \n",
    "        for y in range(self.filter_h):\n",
    "            y_max = y + self.straid*self.out_h\n",
    "            for x in range(self.filter_w):\n",
    "                x_max = x + self.straid*self.out_w\n",
    "                img[:, :, y:y_max:self.straid, x:x_max:self.straid] += dZcol[:, :, y, x, :, :]\n",
    "                \n",
    "        dZ = img[:, :, self.pad:self.h + self.pad, self.pad:self.w + self.pad]\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "    def get_out_put_size2D(n_h, n_w, pad, HF, WF, straid):\n",
    "        #一次元畳み込み後の出力サイズの計算\n",
    "        n_h = (n_h + 2*pad - HF) / straid + 1 \n",
    "        n_w = (n_w + 2*pad - WF) / straid + 1\n",
    "        return n_h, n_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】最大プーリング層の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, pool_h, pool_w, straid=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.straid = straid\n",
    "        self.pad = pad\n",
    "        self.m = None\n",
    "        self.c = None\n",
    "        self.h = None\n",
    "        self.w = None\n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.m, self.c, self.h, self.w = X.shape\n",
    "        if self.out_h is None:\n",
    "            self.out_h = int((self.h - self.pool_h) / self.straid + 1)\n",
    "            self.out_w =  int((self.w - self.pool_w) / self.straid + 1)\n",
    "\n",
    "        \n",
    "        #m2col\n",
    "        col = np.zeros((self.m, self.c, self.pool_h, self.pool_w, self.out_h, self.out_w))\n",
    "        for y in range(self.pool_h):\n",
    "            y_max = y + self.straid*self.out_h\n",
    "            for x in range(self.pool_w):\n",
    "                x_max = x + self.straid*self.out_w\n",
    "                col[:, :, y, x, :, :] = X[:, :, y:y_max:self.straid, x:x_max:self.straid]\n",
    "                \n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(self.m*self.out_h*self.out_w, -1)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        #マックスとる\n",
    "        A = np.max(col, axis=1)\n",
    "        A = A.reshape(self.m, self.out_h, self.out_w, self.c).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.x = X\n",
    "        self.arg_max = np.argmax(col, axis=1)\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dA = dA.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dA.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dA.flatten()\n",
    "        dmax = dmax.reshape(dA.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dX = self.col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.straid, self.pad)\n",
    "        \n",
    "        \n",
    "        #col2im\n",
    "        #dcol = dcol.reshape(self.m, self.out_h, self.out_w, self.c, self.pool_h, self.pool_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        #img = np.zeros((self.m, self.c, self.h + 2*self.pad + self.straid - 1, self.out_w + 2*self.pad + self.straid - 1))\n",
    "        \n",
    "        #for y in range(self.pool_h):\n",
    "            #y_max = y + self.straid*self.out_h\n",
    "            #for x in range(self.pool_w):\n",
    "                #x_max = x + self.straid*self.out_w\n",
    "                #img[:, :, y:y_max:self.straid, x:x_max:self.straid] += dcol[:, :, y, x, :, :]\n",
    "                \n",
    "        #dX = img[:, :, self.pad:self.h + self.pad, self.pad:self.w + self.pad]\n",
    "        \n",
    "        return dX\n",
    "\n",
    "    \n",
    "    def col2im(self, col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        col :\n",
    "        input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "        filter_h :\n",
    "        filter_w\n",
    "        stride\n",
    "        pad\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        N, C, H, W = input_shape\n",
    "        out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "        out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "        col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "        img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "        for y in range(filter_h):\n",
    "            y_max = y + stride*out_h\n",
    "            for x in range(filter_w):\n",
    "                x_max = x + stride*out_w\n",
    "                img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "        return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#データのロード\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#フラットにする\n",
    "#X_train = x_train.reshape(-1, 784)\n",
    "#X_test = x_test.reshape(-1, 784)\n",
    "#スケール合わせ\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "#onehot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "#sprit train and val\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[1]\n",
    "model = ScratchDeepNeuralNetrowkClassifier2(n_features=n, batch_size=50, epoch=20, verbose=True)\n",
    "\n",
    "model.add_sim(Conv2d(3,3, in_channel=1, initializer=SimpleInitializer(), optimizer=SGD(lr=0.01), straid=1, pad=1, out_channel=64))\n",
    "model.add_sim(ReLU())\n",
    "model.add_sim(MaxPool2D(2,2, straid=2, pad=0))\n",
    "model.add_sim(Conv2d(3,3, in_channel=64, initializer=SimpleInitializer(), optimizer=SGD(lr=0.01), straid=1, pad=1, out_channel=64))\n",
    "model.add_sim(ReLU())\n",
    "model.add_sim(MaxPool2D(2,2, straid=2, pad=0))\n",
    "model.add_sim(Flatten())\n",
    "model.add_sim(FC(3136, 10, SimpleInitializer(), SGD(lr=0.01)))\n",
    "model.add_sim(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss: 2.301727974563899 val_loss: 2.302256144810497 acc: 0.11333333333333333\n",
      "epoch:2 train_loss: 2.3002295596308624 val_loss: 2.3018423236983105 acc: 0.11333333333333333\n",
      "epoch:3 train_loss: 2.2976620327473496 val_loss: 2.3009745547173166 acc: 0.11333333333333333\n",
      "epoch:4 train_loss: 2.292297741857023 val_loss: 2.2988516434655186 acc: 0.16333333333333333\n",
      "epoch:5 train_loss: 2.2786938127768663 val_loss: 2.293547593020684 acc: 0.19\n",
      "epoch:6 train_loss: 2.2379482449917876 val_loss: 2.276982512766611 acc: 0.21333333333333335\n",
      "epoch:7 train_loss: 2.1067762070046903 val_loss: 2.208150563488952 acc: 0.30333333333333334\n",
      "epoch:8 train_loss: 1.6972525064238475 val_loss: 1.8578082480536795 acc: 0.35\n",
      "epoch:9 train_loss: 1.7759211654890783 val_loss: 1.957414731161231 acc: 0.4266666666666667\n",
      "epoch:10 train_loss: 1.4088253927696535 val_loss: 1.5718838797981205 acc: 0.55\n",
      "epoch:11 train_loss: 0.7729141385565257 val_loss: 1.020412002894583 acc: 0.6666666666666666\n",
      "epoch:12 train_loss: 0.7003277234846929 val_loss: 0.9757970056450012 acc: 0.7\n",
      "epoch:13 train_loss: 0.5522430066460826 val_loss: 0.8940366299399976 acc: 0.7133333333333334\n",
      "epoch:14 train_loss: 0.3702142376710267 val_loss: 0.6693067569909272 acc: 0.8\n",
      "epoch:15 train_loss: 0.43635250198056386 val_loss: 0.7116059086636445 acc: 0.7766666666666666\n",
      "epoch:16 train_loss: 0.293940755564626 val_loss: 0.5701515155614209 acc: 0.83\n",
      "epoch:17 train_loss: 0.2903763578802 val_loss: 0.5684689319257965 acc: 0.8066666666666666\n",
      "epoch:18 train_loss: 0.26842731068610753 val_loss: 0.5733683696271955 acc: 0.8\n",
      "epoch:19 train_loss: 0.24631642521951466 val_loss: 0.5698809133997959 acc: 0.8066666666666666\n",
      "epoch:20 train_loss: 0.2242147800607893 val_loss: 0.5702425483934472 acc: 0.8066666666666666\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train[:300],y_train[:300], X_val[:300], y_val[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_learning_curve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
